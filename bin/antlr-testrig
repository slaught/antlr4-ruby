#!/usr/bin/env ruby
# encoding: ASCII-8BIT
# encoding: binary
#
# Copyright (c) 2014 Chad Slaughter 
# License: antlr4-ruby/LICENSE
#alias grun "java -cp $CLASSPATH org.antlr.v4.runtime.misc.TestRig"
# java org.antlr.v4.runtime.misc.TestRig GrammarName startRuleName
#   [-tokens] [-tree] [-gui] [-ps file.ps] [-encoding encodingname]
#   [-trace] [-diagnostics] [-SLL]
#   [input-filename(s)]
# Use startRuleName='tokens' if GrammarName is a lexer grammar.

require 'yaml'
require 'pathname'

require "bundler/setup"

def app_dir
  (Pathname.new(File.dirname($0)) + "..").realpath
end
$: << (Pathname.new(app_dir()) +"lib" ).realpath
$: << (Pathname.new(app_dir()) +"vendor/bundle/rbx/2.1/gems/getopt-declare-1.32/lib" ).realpath



$: << 'lib'
$: << '.'

require 'Getopt/Declare'
require 'antlr4'

$DEBUG = false
$TRACE = false
ARG_DEF= <<EOF
         -g <grammar_name>         Grammar Name as declared in .g4 file 
                                   [required]
         -s <start_rule>           Start rule to use
                                   [required]
         <input_files>...          Example file to parser 
                                   [required]
         -tokens                   Print Tokens 
         
         -trace                    enable trace output
                                    {$TRACE = true }
         -debug                    enable debug output
                                    {$DEBUG = true }

EOF

class RawData

  @@file_io = nil
  @@raw_data =  nil
  def self.start
    @@raw_data = Array.new
  end
  def self.record
    @@raw_data << Rubinius::Metrics.data.to_hash
  end
  def self.fini
    require 'json'
    File.open('rbx.raw.data','a') do |io|
      io.puts @@raw_data.to_json
    end
  end

end


class TreeShapeListener < ParseTreeListener
  def visitTerminal(node)
  end
  def visitErrorNode(node)
  end
  def exitEveryRule(ctx)
  end
  def enterEveryRule(ctx)
			for child in ctx.getChildren() 
					parent = child.parentCtx
				  if not parent.kind_of? RuleNode or parent.getRuleContext() != ctx then
						 raise IllegalStateException.new("Invalid parse tree shape detected.")
          end
      end
  end
end


# def print_tokens(parser, tokenstream)
def print_tokens(grammar_name, start_rule, input)
  parserClass, lexerClass = load_grammar(grammar_name,:lexer)
  inputstream = InputStream.new(input.read)
  lexer = lexerClass.new(inputstream)

#  puts lexer.atn.decisionToState.inspect
  stream = CommonTokenStream.new(lexer)
  stream.fill();

  stream.tokens.each {|tok|
      puts tok
  }
#  puts "Debug DFA & ATN"
#  puts lexer.decisionsToDFA.map{|dfa| dfa.toLexerString }.join("\n")
#  puts lexer.atn.decisionToState.to_s
#
#  parser = parserClass.new(stream)
#  atn = parser.interp.atn
#  puts "ATN States"
#  atn.states.each {|s| 
#      puts "(#{s}) : #{s.class}"
#  }
#  puts "Tokens"
#  atn.states.each {|s| 
#      nexttokens = atn.nextTokens(s).toString(parser.tokenNames)
#      n = parser.tokenNames[s]
#      puts "(#{s}) : #{nexttokens}"
#  }
##################################################################
end
def create_token_stream(fn)
  input = File.open(fn) 
  inputstream = InputStream.new(input.read)
  lexer = Lexer.new(inputstream)
  stream = CommonTokenStream.new(lexer)
end
def parse_example(grammar_name, start_rule, input) 
  parserClass, lexerClass = load_grammar(grammar_name)
  inputstream = InputStream.new(input.read)
  lexer = lexerClass.new(inputstream)

  stream = CommonTokenStream.new(lexer)
  parser = parserClass.new(stream)
  parser.setTrace($TRACE)
  parser.buildParseTrees = true 
  tree = parser.send(start_rule.to_sym) 
  ParseTreeWalker.DEFAULT.walk(TreeShapeListener.new(), tree)
end

def load_grammar(grammar_name,selection=:all)
  if selection == :all then
   [ load_grammar_file(grammar_name, 'Parser'), load_grammar_file(grammar_name, 'Lexer') ]
  elsif selection == :lexer then
   [ nil, load_grammar_file(grammar_name, 'Lexer') ]
  end
end
def load_grammar_file(grammar_name, suffix)
    n = "#{grammar_name}#{suffix}"
    require n
    puts "#{n.inspect} -> #{n.to_sym.inspect}" if $DEBUG
    kls = Object.const_get n.to_sym
end

def main(args)
  grammar_name = args['-g']
  start_rule = args['-s']

#  puts args.inspect

  
  input = nil
  args['<input_files>'].each do |in_file|
      input = File.open(in_file)
      begin 
        RawData.start
        puts "#{grammar_name}: #{in_file}"
        if args['-tokens'] then
          print_tokens(grammar_name, start_rule, input)
        else
           parse_example(grammar_name, start_rule, input) 
        end
        RawData.fini
      ensure
          input.close 
      end
  end
end

main(Getopt::Declare.new(ARG_DEF))

__END__
